Automatically generated by Mendeley Desktop 1.19.5
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop
@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
CTLuse_forced_etal       = "yes",
CTLmax_names_forced_etal = "3",
CTLnames_show_etal       = "2" }
@article{Hennemann2017,
abstract = {eHealth interventions can be effective in treating health problems. However, adoption in inpatient routine care seems limited. The present study therefore aimed to investigate barriers and facilitators to acceptance of eHealth interventions and of online aftercare in particular in health professionals of inpatient treatment. A total of 152 out of 287 health professionals of various professional groups in four inpatient rehabilitation facilities filled out a self-administered web-based questionnaire (response rate: 53{\%}); 128 individuals were eligible for further data analysis. Acceptance and possible predictors were investigated with a complex research model based on the Unified Theory of Acceptance and Use of Technology. Acceptance of eHealth interventions was rather low (M = 2.47, SD = 0.98); however, acceptance of online aftercare was moderate (M = 3.08, SD = 0.96, t(127) = 8.22, p {\textless}.001), and eHealth literacy was elevated. Social influence, performance expectancy, and treatment-related internet and mobile use significantly predicted overall acceptance. No differences were found between professional and age groups. Although acceptance of eHealth interventions was limited in health professionals of inpatient treatment, moderate acceptance of online aftercare for work-related stress implies a basis for future implementation. Tailored eHealth education addressing misconceptions about inferiority and incongruity with conventional treatment considering the systemic aspect of acceptance formation are needed.},
author = {Hennemann, Severin and Beutel, Manfred E. and Zwerenz, R{\"{u}}diger},
doi = {10.1080/10810730.2017.1284286},
issn = {10870415},
journal = {Journal of Health Communication},
month = {mar},
number = {3},
pages = {274--284},
pmid = {28248626},
publisher = {Taylor and Francis Inc.},
title = {{Ready for eHealth? Health Professionals' Acceptance and Adoption of eHealth Interventions in Inpatient Routine Care}},
volume = {22},
year = {2017}
}
@article{Engineeringa,
author = {Engineering, Audiovisual Systems},
file = {:home/fabio/mestrado/dissertacao/related{\_}thesis/BSc{\_}thesis.pdf:pdf},
number = {January 2017},
title = {{SKIN LESION DETECTION FROM DERMOSCOPIC IMAGES USING CONVOLUTIONAL NEURAL NETWORKS Submitted to the Faculty of the Escola T ` o de Barcelona a Romero L ´ opez In partial fulfillment of the requirements for the degree in Audiovisual Systems Engineering Advi}}
}
@inproceedings{Baylor2017,
abstract = {Creating and maintaining a platform for reliably producing and deploying machine learning models requires careful orchestration of many components-a learner for generating models based on training data, modules for analyzing and validating both data as well as models, and finally infrastructure for serving models in production. This becomes particularly challenging when data changes over time and fresh models need to be produced continuously. Unfortunately, such orchestration is often done ad hoc using glue code and custom scripts developed by individual teams for specific use cases, leading to duplicated effort and fragile systems with high technical debt. We present TensorFlow Extended (TFX), a TensorFlow-based general-purpose machine learning platform implemented at Google. By integrating the aforementioned components into one platform, we were able to standardize the components , simplify the platform configuration, and reduce the time to production from the order of months to weeks, while providing platform stability that minimizes disruptions. We present the case study of one deployment of TFX in the Google Play app store, where the machine learning models are refreshed continuously as new data arrive. Deploying TFX led to reduced custom code, faster experiment cycles, and a 2{\%} increase in app installs resulting from improved data and model analysis.},
author = {Baylor, Denis and Breck, Eric and Cheng, Heng-Tze and Fiedel, Noah and {Yu Foo}, Chuan and Haque, Zakaria and Haykal, Salem and Ispir, Mustafa and Jain, Vihan and Koc, Levent and {Yuen Koo}, Chiu and Lew, Lukasz and Mewald, Clemens and {Naresh Modi}, Akshay and Polyzotis, Neoklis and Ramesh, Sukriti and Roy, Sudip and {Euijong Whang}, Steven and Wicke, Martin and Wilkiewicz, Jarek and Zhang, Xin and Zinkevich, Martin},
doi = {10.1145/3097983.3098021},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baylor et al. - 2017 - TFX A TensorFlow-Based Production-Scale Machine Learning Platform.pdf:pdf},
title = {{TFX: A TensorFlow-Based Production-Scale Machine Learning Platform}},
url = {http://dx.doi.org/10.1145/3097983.3098021},
year = {2017}
}
@inproceedings{Deng2010,
abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ldquoImageNetrdquo, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and {Kai Li} and {Li Fei-Fei}},
doi = {10.1109/cvpr.2009.5206848},
month = {mar},
pages = {248--255},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
title = {{ImageNet: A large-scale hierarchical image database}},
year = {2010}
}
@misc{chollet2015keras,
author = {Chollet, Fran{\c{c}}ois and Others},
howpublished = {$\backslash$url{\{}https://github.com/fchollet/keras{\}}},
publisher = {GitHub},
title = {{Keras}},
year = {2015}
}
@misc{Haenssle2018,
abstract = {Background: Deep learning convolutional neural networks (CNN) May facilitate melanoma detection, but data comparing a CNN's diagnostic performance to larger groups of dermatologists are lacking. Methods: Google's Inception v4 CNN architecture was trained and validated using dermoscopic images and corresponding diagnoses. In a comparative cross-sectional reader study a 100-image test-set was used (level-I: dermoscopy only; level-II: dermoscopy plus clinical information and images). Main outcome measures were sensitivity, specificity and area under the curve (AUC) of receiver operating characteristics (ROC) for diagnostic classification (dichotomous) of lesions by the CNN versus an international group of 58 dermatologists during level-I or -II of the reader study. Secondary end points included the dermatologists' diagnostic performance in their management decisions and differences in the diagnostic performance of dermatologists during level-I and -II of the reader study. Additionally, the CNN's performance was compared with the top-five algorithms of the 2016 International Symposium on Biomedical Imaging (ISBI) challenge. Results: In level-I dermatologists achieved a mean (6standard deviation) sensitivity and specificity for lesion classification of 86.6{\%} (69.3{\%}) and 71.3{\%} (611.2{\%}), respectively. More clinical information (level-II) improved the sensitivity to 88.9{\%} (69.6{\%}, P ¼ 0.19) and specificity to 75.7{\%} (611.7{\%}, P {\textless} 0.05). The CNN ROC curve revealed a higher specificity of 82.5{\%} when compared with dermatologists in level-I (71.3{\%}, P {\textless} 0.01) and level-II (75.7{\%}, P {\textless} 0.01) at their sensitivities of 86.6{\%} and 88.9{\%}, respectively. The CNN ROC AUC was greater than the mean ROC area of dermatologists (0.86 versus 0.79, P {\textless} 0.01). The CNN scored results close to the top three algorithms of the ISBI 2016 challenge. Conclusions: For the first time we compared a CNN's diagnostic performance with a large international group of 58 dermatologists, including 30 experts. Most dermatologists were outperformed by the CNN. Irrespective of any physicians' experience, they May benefit from assistance by a CNN's image classification.},
author = {Haenssle, H. A. and Fink, C. and Schneiderbauer, R. and Toberer, F. and Buhl, T. and Blum, A. and Kalloo, A. and {Ben Hadj Hassen}, A. and Thomas, L. and Enk, A. and Uhlmann, L.},
booktitle = {Annals of Oncology},
doi = {10.1093/annonc/mdy166},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haenssle et al. - 2018 - Man against Machine Diagnostic performance of a deep learning convolutional neural network for dermoscopic mela.pdf:pdf},
issn = {15698041},
keywords = {Automated melanoma detection,Computer algorithm,Deep learning convolutional neural network,Dermoscopy,Melanocytic nevi,Melanoma},
number = {8},
pages = {1836--1842},
publisher = {Oxford University Press},
title = {{Man against Machine: Diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists}},
volume = {29},
year = {2018}
}
@article{Esteva2017,
abstract = {An artificial intelligence trained to classify images of skin lesions as benign lesions or malignant skin cancers achieves the accuracy of board-certified dermatologists.},
author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
doi = {10.1038/nature21056},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Esteva et al. - 2017 - Dermatologist-level classification of skin cancer with deep neural networks.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Diagnosis,Machine learning,Skin cancer},
month = {feb},
number = {7639},
pages = {115--118},
publisher = {Nature Publishing Group},
title = {{Dermatologist-level classification of skin cancer with deep neural networks}},
url = {http://www.nature.com/articles/nature21056},
volume = {542},
year = {2017}
}
@misc{isic2019first,
abstract = {In this paper we describe our method for the ISIC 2019 Skin Lesion Classification Challenge. The challenge's goal is to classify skin lesions based on dermoscopic images. A diverse dataset of 25 000 images was provided for training, containing images from eight classes. The final test set contains an additional, unknown class. We address this challenging problem with a simple, data driven approach by including external data with skin lesions types that are not present in the training set. Furthermore , multi-class skin lesion classification comes with the problem of severe class imbalance. We try to overcome this problem using loss balancing. Also, the dataset contains images with very different resolutions. We take care of this property by considering different model input resolutions and different cropping strategies. We aggregate all our models with an ensembling strategy where we search for the optimal subset of models. Our final ensemble achieves a balanced accuracy of 70 ± 5 {\%} using five-fold cross-validation.},
author = {Gessert, Nils and Nielsen, Maximilian and Shaikh, Mohsin and Werner, Ren{\'{e}} and Schlaefer, Alexander},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gessert et al. - Unknown - Skin Lesion Classification Using Loss Balancing and Ensembles of Multi-Resolution EfficientNets.pdf:pdf;:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gessert et al. - Unknown - Skin Lesion Classification Using Loss Balancing and Ensembles of Multi-Resolution EfficientNets(2).pdf:pdf},
keywords = {Deep Learning,EfficientNet,Loss Balancing,Skin Lesion Classification},
title = {{Skin Lesion Classification Using Loss Balancing and Ensembles of Multi-Resolution EfficientNets}}
}
@article{Miotto2017,
abstract = {Gaining knowledge and actionable insights from complex, high-dimensional and heterogeneous biomedical data remains a key challenge in transforming health care. Various types of data have been emerging in modern biomedical research, including electronic health records, imaging, -omics, sensor data and text, which are complex, heterogeneous, poorly annotated and generally unstructured. Traditional data mining and statistical learning approaches typically need to first perform feature engineering to obtain effective and more robust features from those data, and then build prediction or clustering models on top of them. There are lots of challenges on both steps in a scenario of complicated data and lacking of sufficient domain knowledge. The latest advances in deep learning technologies provide new effective paradigms to obtain end-to-end learning models from complex data. In this article, we review the recent literature on applying deep learning technologies to advance the health care domain. Based on the analyzed work, we suggest that deep learning approaches could be the vehicle for translating big biomedical data into improved human health. However, we also note limitations and needs for improved methods development and applications, especially in terms of ease-of-understanding for domain experts and citizen scientists. We discuss such challenges and suggest developing holistic and meaningful interpretable architectures to bridge deep learning models and human interpretability.},
author = {Miotto, Riccardo and Wang, Fei and Wang, Shuang and Jiang, Xiaoqian and Dudley, Joel T.},
doi = {10.1093/bib/bbx044},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miotto et al. - 2017 - Deep learning for healthcare Review, opportunities and challenges.pdf:pdf},
issn = {14774054},
journal = {Briefings in Bioinformatics},
keywords = {Biomedical informatics,Deep learning,Electronic health records,Genomics,Health care,Translational bioinformatics},
month = {may},
number = {6},
pages = {1236--1246},
publisher = {Oxford University Press},
title = {{Deep learning for healthcare: Review, opportunities and challenges}},
volume = {19},
year = {2017}
}
@book{Grus,
abstract = {Book about data science},
author = {Grus, Joel},
file = {:home/fabio/mestrado/dissertacao/books/[Joel{\_}Grus]{\_}Data{\_}Science{\_}from{\_}Scratch{\_}First{\_}Princ.pdf:pdf},
isbn = {9781491901427},
publisher = {O'Reilly Media},
title = {{Data Science From Scratch}},
year = {2015}
}
@misc{isic2019,
title = {{ISIC 2019}},
url = {https://challenge2019.isic-archive.com/},
urldate = {2019-11-23}
}
@misc{Bastien,
abstract = {Theano is a linear algebra compiler that optimizes a user's symbolically-specified mathematical computations to produce efficient low-level implementations. In this paper, we present new features and efficiency improvements to Theano, and benchmarks demonstrating Theano's performance relative to Torch7, a recently introduced machine learning library, and to RNNLM, a C++ library targeted at recurrent neural networks.},
archivePrefix = {arXiv},
arxivId = {1211.5590v1},
author = {Bastien, Fr{\'{e}}d{\'{e}}ric and {Pascal Lamblin}, Nouizorg and Bergstra, James and Goodfellow, Ian and Bergeron, Arnaud and Bouchard, Nicolas and Warde-Farley, David and Bengio, Yoshua},
eprint = {1211.5590v1},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bastien et al. - Unknown - Theano new features and speed improvements.pdf:pdf},
title = {{Theano: new features and speed improvements}}
}
@article{Greenspan2016,
author = {Greenspan, Hayit and {Van Ginneken}, Bram and Summers, Ronald M.},
doi = {10.1109/TMI.2016.2553401},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Greenspan, Van Ginneken, Summers - 2016 - Guest Editorial Deep Learning in Medical Imaging Overview and Future Promise of an Exciting Ne.pdf:pdf},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
month = {may},
number = {5},
pages = {1153--1159},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Guest Editorial Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique}},
volume = {35},
year = {2016}
}
@misc{yu,
abstract = {Automated melanoma recognition in dermoscopy images is a very challenging task due to the low contrast of skin lesions, the huge intraclass variation of melanomas, the high degree of visual similarity between melanoma and non-melanoma lesions, and the existence of many artifacts in the image. In order to meet these challenges, we propose a novel method for melanoma recognition by leveraging very deep convolutional neural networks (CNNs). Compared with existing methods employing either low-level hand-crafted features or CNNs with shallower architectures, our substantially deeper networks (more than 50 layers) can acquire richer and more discriminative features for more accurate recognition. To take full advantage of very deep networks, we propose a set of schemes to ensure effective training and learning under limited training data. First, we apply the residual learning to cope with the degradation and overfitting problems when a network goes deeper. This technique can ensure that our networks benefit from the performance gains achieved by increasing network depth. Then, we construct a fully convolutional residual network (FCRN) for accurate skin lesion segmentation, and further enhance its capability by incorporating a multi-scale contextual information integration scheme. Finally, we seamlessly integrate the proposed FCRN (for segmentation) and other very deep residual networks (for classification) to form a two-stage framework. This framework enables the classification network to extract more representative and specific features based on segmented results instead of the whole dermoscopy images, further alleviating the insufficiency of training data. The proposed framework is extensively evaluated on ISBI 2016 Skin Lesion Analysis Towards Melanoma Detection Challenge dataset. Experimental results demonstrate the significant performance gains of the proposed framework, ranking the first in classification and the second in segmentation among 25 teams and 28 teams, respectively. This study corroborates that very deep CNNs with effective training mechanisms can be employed to solve complicated medical image analysis tasks, even with limited training data.},
author = {Yu, Lequan and Chen, Hao and Dou, Qi and Qin, Jing and Heng, Pheng Ann},
booktitle = {IEEE Transactions on Medical Imaging},
doi = {10.1109/TMI.2016.2642839},
file = {:home/fabio/Desktop/yu.pdf:pdf},
issn = {1558254X},
keywords = {Automated melanoma recognition,fully convolutional neural networks,residual learning,skin lesion analysis,very deep convolutional neural networks},
month = {apr},
number = {4},
pages = {994--1004},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Automated Melanoma Recognition in Dermoscopy Images via Very Deep Residual Networks}},
volume = {36},
year = {2017}
}
@book{Nielsen2017a,
abstract = {Neural Networks and Deep Learning is a free online book. The book will teach you about: Neural networks, a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data Deep learning, a powerful set of techniques for learning in neural networks Neural networks and deep learning currently provide the best solutions to many problems in image recognition, speech recognition, and natural language processing. This book will teach you many of the core concepts behind neural networks and deep learning.},
author = {Nielsen, Michael},
file = {:home/fabio/mestrado/dissertacao/books/NeuralNetwroks {\&} DeepLearning ebook by Michael Nielsen.pdf:pdf},
pages = {389--411},
title = {{Neural Networks and Deep Learning}},
url = {http://neuralnetworksanddeeplearning.com/},
year = {2018}
}
@phdthesis{maia,
abstract = {Transfer learning is a popular solution to the common problem in deep learning that is the lack of data or the computational resources to train large models from scratch, which skin lesion classification is a prime candidate for because high quality medical imaging data in this domain is scarce. This dissertation studies transfer learning in the domain of skin lesion classification by exploring pre-trained models of the VGG16 architecture (originally trained on ImageNet) and repurposing them for skin lesion classification on the ISIC 2018 dataset. Specifically, models of VGG16 are tested by exhaustively testing the layers at which weights are extracted from and up to which they are frozen from further training, concluding that extracting all layers from VGG16 and fine-tuning the last two convolutional blocks to the ISIC 2018 dataset is the most performant configuration. However different choices of optimizer and learning rates could unveil better models. For comparison, two custom CNN architectures are explored and trained from scratch in a typical end- to-end learning scheme, from which it can be seen that end-to-end learning of CNN is much harder due to the many different hyperparameters that need to be cross-validated on a wide range of values which is computationally intensive to do thoroughly. In conclusion, transfer learning is a much more practical strategy for skin lesion classification and most other computer vision problems.},
author = {Maia, F{\'{a}}bio},
file = {:home/fabio/mestrado/dissertacao/related{\_}thesis/fabio{\_}maia/FabioMaia{\_}Dissertation{\_}TransferLearningSkinLesionClassification.pdf:pdf},
keywords = {binary classification,convolutional neural network,deep learning,medical imaging,skin lesion diagnosis,transfer learning},
school = {Universidade de Aveiro},
title = {{A Study of Transfer Learning for Skin Lesion Classificatio}},
year = {2019}
}
@techreport{Abadi,
abstract = {TensorFlow [1] is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition , computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the Ten-sorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
archivePrefix = {arXiv},
arxivId = {1603.04467v2},
author = {Abadi, Mart{\'{i}}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man{\'{e}}, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vi{\'{e}}gas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang and Research, Google},
eprint = {1603.04467v2},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi et al. - Unknown - TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems.pdf:pdf},
title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}}
}
@book{Goodfellow-et-al-2016,
annote = {$\backslash$url{\{}http://www.deeplearningbook.org{\}}},
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
publisher = {MIT Press},
title = {{Deep Learning}},
year = {2016}
}
@misc{dermengine,
title = {{DermEngine | Visual Search}},
url = {https://www.dermengine.com/en-ca/visual-search},
urldate = {2019-11-21}
}
@misc{Celebi2019,
abstract = {Dermoscopy is a non-invasive skin imaging technique that permits visualization of features of pigmented melanocytic neoplasms that are not discernable by examination with the naked eye. While studies on the automated analysis of dermoscopy images date back to the late 1990s, because of various factors (lack of publicly available datasets, open-source software, computational power, etc.), the field progressed rather slowly in its first two decades. With the release of a large public dataset by the International Skin Imaging Collaboration in 2016, development of open-source software for convolutional neural networks, and the availability of inexpensive graphics processing units, dermoscopy image analysis has recently become a very active research field. In this paper, we present a brief overview of this exciting subfield of medical image analysis, primarily focusing on three aspects of it, namely, segmentation, feature extraction, and classification. We then provide future directions for researchers.},
author = {Celebi, M. Emre and Codella, Noel and Halpern, Allan},
booktitle = {IEEE Journal of Biomedical and Health Informatics},
doi = {10.1109/JBHI.2019.2895803},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Celebi, Codella, Halpern - 2019 - Dermoscopy Image Analysis Overview and Future Directions.pdf:pdf},
issn = {21682194},
keywords = {Skin cancer,computer-aided diagnosis,dermoscopy,dermoscopy image analysis,melanoma},
month = {mar},
number = {2},
pages = {474--478},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Dermoscopy Image Analysis: Overview and Future Directions}},
volume = {23},
year = {2019}
}
@misc{Ng,
abstract = {We consider supervised learning in the presence of very many irrelevant features, and study two different regularization methods for preventing overfitting. Focusing on logistic regression, we show that using L 1 regu-larization of the parameters, the sample complexity (i.e., the number of training examples required to learn "well,") grows only logarithmically in the number of irrelevant features. This logarithmic rate matches the best known bounds for feature selection, and indicates that L 1 regularized logistic regression can be effective even if there are exponentially many irrelevant features as there are training examples. We also give a lower-bound showing that any rotationally invariant algorithm-including logistic regression with L 2 regularization, SVMs, and neural networks trained by backpropagation-has a worst case sample complexity that grows at least linearly in the number of irrelevant features .},
author = {Ng, Andrew},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng - Unknown - Feature selection, L 1 vs. L 2 regularization, and rotational invariance.pdf:pdf},
title = {{Feature selection, L 1 vs. L 2 regularization, and rotational invariance}}
}
@misc{ieeta-collaboration,
author = {Silva, Filipe and Georgieva, P{\'{e}}tia},
file = {:home/fabio/Desktop/IEETA{\_}EPIDERMIS{\_}CollaborativeProposal{\_}01Nov2018.pdf:pdf},
title = {{Machine Learning for Automated Diagnosis of Pigmented Skin Lesions}},
year = {2018}
}
@misc{Foundation2019,
abstract = {Skin Cancer Facts {\&} Statistics - The Skin Cancer Foundation},
title = {{Skin Cancer Facts {\&} Statistics - The Skin Cancer Foundation}},
url = {https://skincancer.org/skin-cancer-information/skin-cancer-facts/},
urldate = {2019-11-10},
year = {2019}
}
@article{Miller2018,
abstract = {Computer science advances and ultra-fast computing speeds find artificial intelligence (AI) broadly benefitting modern society—forecasting weather, recognizing faces, detecting fraud, and deciphering genomics. AI's future role in medical practice remains an unanswered question. Machines (computers) learn to detect patterns not decipherable using biostatistics by processing massive datasets (big data) through layered mathematical models (algorithms). Correcting algorithm mistakes (training) adds to AI predictive model confidence. AI is being successfully applied for image analysis in radiology, pathology, and dermatology, with diagnostic speed exceeding, and accuracy paralleling, medical experts. While diagnostic confidence never reaches 100{\%}, combining machines plus physicians reliably enhances system performance. Cognitive programs are impacting medical practice by applying natural language processing to read the rapidly expanding scientific literature and collate years of diverse electronic medical records. In this and other ways, AI may optimize the care trajectory of chronic disease patients, suggest precision therapies for complex illnesses, reduce medical errors, and improve subject enrollment into clinical trials.},
author = {Miller, D. Douglas and Brown, Eric W.},
doi = {10.1016/J.AMJMED.2017.10.035},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Brown - 2018 - Artificial Intelligence in Medical Practice The Question to the Answer.pdf:pdf},
issn = {0002-9343},
journal = {The American Journal of Medicine},
month = {feb},
number = {2},
pages = {129--133},
publisher = {Elsevier},
title = {{Artificial Intelligence in Medical Practice: The Question to the Answer?}},
url = {https://www.sciencedirect.com/science/article/pii/S0002934317311178?via{\%}3Dihub},
volume = {131},
year = {2018}
}
@misc{March,
abstract = {Confirming a diagnosis of cutaneous melanoma requires obtaining a skin biopsy specimen. However, obtaining numerous biopsy specimens - which often happens in patients with increased melanoma risk - is associated with significant cost and morbidity. While some melanomas are easily recognized by the naked eye, many can be difficult to distinguish from nevi, and therefore there is a need and opportunity to develop new technologies that can facilitate clinical examination and melanoma diagnosis. In part I of this 2-part continuing medical education article, we will review the practical applications of emerging technologies for noninvasive melanoma diagnosis, including mobile (smartphone) applications, multispectral imaging (ie, MoleMate and MelaFind), and electrical impedance spectroscopy (Nevisense).},
author = {March, Jordon and Hand, Matthew and Grossman, Douglas},
booktitle = {Journal of the American Academy of Dermatology},
doi = {10.1016/j.jaad.2015.02.1138},
file = {:home/fabio/Desktop/1-s2.0-S0190962215013791-main.pdf:pdf},
issn = {10976787},
keywords = {Mela Find,Mole Mate,Nevisense,melanoma,mobile app,spectroscopy,teledermatology},
month = {jun},
number = {6},
pages = {929--941},
publisher = {Mosby Inc.},
title = {{Practical application of new technologies for melanoma diagnosis: Part I. Noninvasive approaches}},
volume = {72},
year = {2015}
}
@misc{isic2019second,
abstract = {On the other hand, the images for skin lesion analyzing may be taken by different devices, producing huge variations in scale, resolution, lighting condition, rotation angles etc. Besides, the number of samples for different lesion category can be heavily imbalanced, due to the difference in morbidity over populations. For classification problem, a predictive model would have better performance if the input are sampled from the same distribution. Thus, a carefully designed Abstract: Deep learning based algorithm have become been the first option for analyzing medical images. For skin lesion classification task, dermoscopy imaging is an effective approach of generating high resolution images. The scale and resolution of skin lesion can be of huge variations in the captured images. On the other hand, the number of labelled skin lesion images is relative small for training deep models with well performance. In this article, we describes the motivation, design and results of our approaches for the multi-class skin lesion classification problem, using the dermoscopy images provided in ISIC 2019 Challenge. Our best method can achieve a average accuracy of 75.3{\%} over all the 8 categories based on 5-fold cross validation.},
author = {Zhou, Steven and Zhuang, Yixin and Meng, Rusong},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Zhuang, Meng - Unknown - Multi-Category Skin Lesion Diagnosis Using Dermoscopy Images and Deep CNN Ensembles.pdf:pdf},
title = {{Multi-Category Skin Lesion Diagnosis Using Dermoscopy Images and Deep CNN Ensembles}}
}
@article{alexnet,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%}, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
doi = {10.1145/3065386},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton - 2017 - ImageNet classification with deep convolutional neural networks.pdf:pdf},
issn = {15577317},
journal = {Communications of the ACM},
month = {jun},
number = {6},
pages = {84--90},
publisher = {Association for Computing Machinery},
title = {{ImageNet classification with deep convolutional neural networks}},
volume = {60},
year = {2017}
}
@article{Hinton2012,
abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
eprint = {1207.0580},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton et al. - 2012 - Improving neural networks by preventing co-adaptation of feature detectors.pdf:pdf},
month = {jul},
title = {{Improving neural networks by preventing co-adaptation of feature detectors}},
url = {http://arxiv.org/abs/1207.0580},
year = {2012}
}
@misc{isic2018,
title = {{Task 3: Lesion Diagnosis | ISIC 2018}},
url = {https://challenge2018.isic-archive.com/task3/},
urldate = {2019-11-23}
}
@article{Bray2018,
abstract = {This article provides a status report on the global burden of cancer worldwide using the GLOBOCAN 2018 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer, with a focus on geographic variability across 20 world regions. There will be an estimated 18.1 million new cancer cases (17.0 million excluding nonmelanoma skin cancer) and 9.6 million cancer deaths (9.5 million excluding nonmelanoma skin cancer) in 2018. In both sexes combined, lung cancer is the most commonly diagnosed cancer (11.6{\%} of the total cases) and the leading cause of cancer death (18.4{\%} of the total cancer deaths), closely followed by female breast cancer (11.6{\%}), prostate cancer (7.1{\%}), and colorectal cancer (6.1{\%}) for incidence and colorectal cancer (9.2{\%}), stomach cancer (8.2{\%}), and liver cancer (8.2{\%}) for mortality. Lung cancer is the most frequent cancer and the leading cause of cancer death among males, followed by prostate and colorectal cancer (for incidence) and liver and stomach cancer (for mortality). Among females, breast cancer is the most commonly diagnosed cancer and the leading cause of cancer death, followed by colorectal and lung cancer (for incidence), and vice versa (for mortality); cervical cancer ranks fourth for both incidence and mortality. The most frequently diagnosed cancer and the leading cause of cancer death, however, substantially vary across countries and within each country depending on the degree of economic development and associated social and life style factors. It is noteworthy that high-quality cancer registry data, the basis for planning and implementing evidence-based cancer control programs, are not available in most low- and middle-income countries. The Global Initiative for Cancer Registry Development is an international partnership that supports better estimation, as well as the collection and use of local data, to prioritize and evaluate national cancer control efforts. CA: A Cancer Journal for Clinicians 2018;0:1-31. {\textcopyright} 2018 American Cancer Society.},
author = {Bray, Freddie and Ferlay, Jacques and Soerjomataram, Isabelle and Siegel, Rebecca L. and Torre, Lindsey A. and Jemal, Ahmedin},
doi = {10.3322/caac.21492},
issn = {1542-4863},
journal = {CA: A Cancer Journal for Clinicians},
month = {nov},
number = {6},
pages = {394--424},
pmid = {30207593},
publisher = {American Cancer Society},
title = {{Global cancer statistics 2018: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries}},
volume = {68},
year = {2018}
}
@book{DipanjanSarkarRaghavBali2018,
author = {{Dipanjan Sarkar, Raghav Bali}, Tamoghna Ghosh},
edition = {First},
publisher = {Packt Publishing},
title = {{Hands-On Transfer Learning with Python}},
year = {2018}
}
@techreport{pytorch,
abstract = {In this article, we describe an automatic differentiation module of PyTorch-a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and Facebook, Zachary Devito and Research, A I and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Srl, Orobix and Lerer, Adam},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paszke et al. - Unknown - Automatic differentiation in PyTorch.pdf:pdf},
title = {{Automatic differentiation in PyTorch}},
year = {2017}
}
@techreport{Canziani,
abstract = {Since the emergence of Deep Neural Networks (DNNs) as a prominent technique in the field of computer vision, the ImageNet classification challenge has played a major role in advancing the state-of-the-art. While accuracy figures have steadily increased, the resource utilisation of winning models has not been properly taken into account. In this work, we present a comprehensive analysis of important met-rics in practical applications: accuracy, memory footprint, parameters, operations count, inference time and power consumption. Key findings are: (1) power consumption is independent of batch size and architecture; (2) accuracy and inference time are in a hyperbolic relationship; (3) energy constraint is an upper bound on the maximum achievable accuracy and model complexity; (4) the number of operations is a reliable estimate of the inference time. We believe our analysis provides a compelling set of information that helps design and engineer efficient DNNs.},
archivePrefix = {arXiv},
arxivId = {1605.07678v4},
author = {Canziani, Alfredo and Culurciello, Eugenio and Paszke, Adam},
eprint = {1605.07678v4},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Canziani, Culurciello, Paszke - Unknown - AN ANALYSIS OF DEEP NEURAL NETWORK MODELS FOR PRACTICAL APPLICATIONS.pdf:pdf},
title = {{AN ANALYSIS OF DEEP NEURAL NETWORK MODELS FOR PRACTICAL APPLICATIONS}}
}
@inproceedings{Pomponiu2016,
abstract = {Nowadays, the occurrence of skin cancer cases has grown worldwide due to the extended exposure to the harmful radiation from the Sun. Most common approach to detect the malignancy of skin moles is by visual inspection performed by an expert dermatologist, using a set of specific clinical rules. Computer-aided diagnosis, based on skin mole imaging, is another concurrent method which has experienced major advancements due to improvement of imaging sensors and processing power. However, these schemes use hand-crafted features which are difficult to tune and perform poorly on new cases due to lack of generalization power. In this study we present a method that use a pretrained deep neural network (DNN) to automatically extract a set of representative features that can be later used to diagnose a sample of skin lesion for malignancy. The experimental tests carried out on a clinical dataset show that the classification performance using DNN-based features performs better than the state-of-the-art techniques.},
author = {Pomponiu, V. and Nejati, H. and Cheung, N. M.},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2016.7532834},
isbn = {9781467399616},
issn = {15224880},
keywords = {Deep neural networks,Feature extraction,Malignant melanoma,Skin mole classification,Transfer learning},
month = {aug},
pages = {2623--2627},
publisher = {IEEE Computer Society},
title = {{Deepmole: Deep neural networks for skin mole lesion classification}},
volume = {2016-Augus},
year = {2016}
}
@misc{msk,
abstract = {This article describes the design, implementation, and results of the latest installment of the dermoscopic image analysis benchmark challenge. The goal is to support research and development of algorithms for automated diagnosis of melanoma, the most lethal skin cancer. The challenge was divided into 3 tasks: lesion segmentation, feature detection, and disease classification. Participation involved 593 registrations, 81 pre-submissions, 46 finalized submissions (including a 4-page manuscript), and approximately 50 attendees, making this the largest standardized and comparative study in this field to date. While the official challenge duration and ranking of participants has concluded, the dataset snapshots remain available for further research and development.},
archivePrefix = {arXiv},
arxivId = {1710.05006},
author = {Codella, Noel C. F.},
eprint = {1710.05006},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Codella et al. - 2017 - Skin Lesion Analysis Toward Melanoma Detection A Challenge at the 2017 International Symposium on Biomedical Ima.pdf:pdf},
month = {oct},
title = {{Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)}},
url = {http://arxiv.org/abs/1710.05006},
year = {2017}
}
@misc{ilsvrc,
abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
archivePrefix = {arXiv},
arxivId = {1409.0575},
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
booktitle = {International Journal of Computer Vision},
doi = {10.1007/s11263-015-0816-y},
eprint = {1409.0575},
issn = {15731405},
keywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},
month = {dec},
number = {3},
pages = {211--252},
publisher = {Springer New York LLC},
title = {{ImageNet Large Scale Visual Recognition Challenge}},
volume = {115},
year = {2015}
}
@misc{Ly2019,
abstract = {Deep learning neural networks have made significant progress in image analysis and have been used for skin cancer recognition. Early detection and proper treatments for malignant skin cancer cases are vital to ensure high survival rate in patients. We present a novel deep learning based convolutional neural network (CNN) model for generating compatible models on mobile platforms such as Android and iOS. The proposed model was tested on the grand challenge PHDB melanoma dataset. The best performing proposed model excels in the following ways: (1) it outperforms the baseline model in terms of accuracy by 1{\%}; (2) it consists of 60{\%} fewer parameters compared to the base model and thereby it is more efficient on mobile platforms. Furthermore, the model is more compact and retains high accuracy without the need to be downsized; (3) in conjunction with advanced regularization techniques such as dropout and data augmentation, the proposed CNN model excelled when implemented on state-of-the-art frameworks such as Keras and TensorFlow. Additionally, we were able to successfully deploy it on the iOS and Android mobile systems. The proposed model could also be lucrative towards other datasets for image classification on mobile platform},
author = {Ly, Phillip and Bein, Doina and Verma, Abhishek},
doi = {10.1109/uemcon.2018.8796628},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ly, Bein, Verma - 2019 - New Compact Deep Learning Model for Skin Cancer Recognition(2).pdf:pdf},
isbn = {9781538676936},
keywords = {CNN,Deep Learning,Melanoma,Mobile Systems,PHDB,Skin Cancer},
month = {aug},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
title = {{New Compact Deep Learning Model for Skin Cancer Recognition}},
year = {2019}
}
@misc{Ali2017,
abstract = {In this paper, we propose a method for classifying melanoma images into benign and malignant using Convolutional Neural Networks (CNNs). Having an automated method for melanoma detection will assist dermatologists in the early diagnosis of this type of skin cancer. A regular convolutional network employing a modest number of parameters is used to detect melanoma images. The architecture is used to classify the dataset of the ISBI 2016 challenge in melanoma classification. The dataset was not segmented or cropped prior to classification. The proposed method was then evaluated for accuracy, sensitivity and specificity. Comparisons with the winning entry in the competition demonstrate that one can achieve a performance level comparable to state-of-the-art using standard convolutional neural network architectures that employ a lower number of parameters.},
author = {Ali, Aya Abu and Al-Marzouqi, Hasan},
booktitle = {2017 International Conference on Electrical and Computing Technologies and Applications, ICECTA 2017},
doi = {10.1109/ICECTA.2017.8252041},
isbn = {9781538608722},
month = {jun},
pages = {1--5},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Melanoma detection using regular convolutional neural networks}},
volume = {2018-Janua},
year = {2017}
}
@article{Mar2018,
author = {Mar, V. J. and Soyer, H. P.},
doi = {10.1093/annonc/mdy193},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mar, Soyer - 2018 - Artificial intelligence for melanoma diagnosis How can we deliver on the promise.pdf:pdf},
issn = {15698041},
journal = {Annals of Oncology},
number = {8},
publisher = {Oxford University Press},
title = {{Artificial intelligence for melanoma diagnosis: How can we deliver on the promise?}},
volume = {29},
year = {2018}
}
@inproceedings{Pham2018,
abstract = {Deep CNN techniques have dramatically become the state of the art in image classification. However, applying high-capacity Deep CNN in medical image analysis has been impeded because of scarcity of labeled data. This study has two primary contributions: first, we propose a classification model to improve performance of classification of skin lesion using Deep CNN and Data Augmentation. Second, we demonstrate the use of image data augmentation for overcoming the problem of data limitation and examine the influence of different number of augmented samples on the performance of different classifiers. The proposed classification system is evaluated using the largest public skin lesion testing dataset, containing 600 testing images, and 6,162 training images. New state-of-the-art performance result is archived with AUC (89.2{\%} vs. 87.4{\%}), AP (73.9{\%} vs. 71.5{\%}), and ACC (89.0{\%} vs. 87.2{\%}). In additional, we explore the influence of each image augmentation on the three classifiers and observe that performance of each classifier is influenced differently by each augmentation and has better results comparing with traditional methods. Thus, it is suggested that the performance of skin cancer classification and medial image classification could be improved further by applying data augmentation.},
author = {Pham, Tri Cong and Luong, Chi Mai and Visani, Muriel and Hoang, Van Dung},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-75420-8_54},
file = {:home/fabio/Desktop/OfficialPubli{\_}10752{\_}ACIIDS18{\_}DeepCNNandDataAugmentationforSkinLesionClassification.pdf:pdf},
isbn = {9783319754192},
issn = {16113349},
keywords = {Data augmentation,Deep learning,Medical image,Melanoma classification,Skin cancer},
pages = {573--582},
publisher = {Springer Verlag},
title = {{Deep CNN and Data Augmentation for Skin Lesion Classification}},
volume = {10752 LNAI},
year = {2018}
}
@misc{bcn_20000,
abstract = {This article summarizes the BCN20000 dataset, composed of 19424 dermoscopic images of skin lesions captured from 2010 to 2016 in the facilities of the Hospital Cl$\backslash$'inic in Barcelona. With this dataset, we aim to study the problem of unconstrained classification of dermoscopic images of skin cancer, including lesions found in hard-to-diagnose locations (nails and mucosa), large lesions which do not fit in the aperture of the dermoscopy device, and hypo-pigmented lesions. The BCN20000 will be provided to the participants of the ISIC Challenge 2019, where they will be asked to train algorithms to classify dermoscopic images of skin cancer automatically.},
archivePrefix = {arXiv},
arxivId = {1908.02288},
author = {Combalia, Marc and Codella, Noel C. F. and Rotemberg, Veronica and Helba, Brian and Vilaplana, Veronica and Reiter, Ofer and Carrera, Cristina and Barreiro, Alicia and Halpern, Allan C. and Puig, Susana and Malvehy, Josep},
eprint = {1908.02288},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Combalia et al. - 2019 - BCN20000 Dermoscopic Lesions in the Wild.pdf:pdf},
month = {aug},
title = {{BCN20000: Dermoscopic Lesions in the Wild}},
url = {http://arxiv.org/abs/1908.02288},
year = {2019}
}
@article{Yuan2017,
abstract = {Automatic skin lesion segmentation on dermoscopic images is an essential step in computer-aided diagnosis of melanoma. However, this task is challenging due to significant variations of lesion appearances across different patients. This challenge is further exacerbated when dealing with a large amount of image data. In this paper, we extended our previous work by developing a deeper network architecture with smaller kernels to enhance its discriminant capacity. In addition, we explicitly included color information from multiple color spaces to facilitate network training and thus to further improve the segmentation performance. We extensively evaluated our method on the ISBI 2017 skin lesion segmentation challenge. By training with the 2000 challenge training images, our method achieved an average Jaccard Index (JA) of 0.765 on the 600 challenge testing images, which ranked itself in the first place in the challenge},
archivePrefix = {arXiv},
arxivId = {1709.09780},
author = {Yuan, Yading and Lo, Yeh-Chi},
eprint = {1709.09780},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan, Lo - 2017 - Improving Dermoscopic Image Segmentation with Enhanced Convolutional-Deconvolutional Networks(2).pdf:pdf},
month = {sep},
title = {{Improving Dermoscopic Image Segmentation with Enhanced Convolutional-Deconvolutional Networks}},
url = {http://arxiv.org/abs/1709.09780},
year = {2017}
}
@misc{isic2018top3,
author = {Nozdryn-Plotnicki, Aleksey and Yap, Jordan and Yolland, William},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nozdryn-Plotnicki, Yap, Yolland - Unknown - Ensembling Convolutional Neural Networks for Skin Cancer Classification.pdf:pdf;:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nozdryn-Plotnicki, Yap, Yolland - Unknown - Ensembling Convolutional Neural Networks for Skin Cancer Classification(2).pdf:pdf},
title = {{Ensembling Convolutional Neural Networks for Skin Cancer Classification}}
}
@misc{vggnet,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisa-tion and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556v6},
author = {Simonyan, Karen and Zisserman, Andrew},
eprint = {1409.1556v6},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2015 - VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION.pdf:pdf},
title = {{Very Deep Convolutional Networks For Large-Scale Image Recogntinion}},
url = {http://www.robots.ox.ac.uk/},
year = {2015}
}
@misc{ieeta-review,
abstract = {ieeta-review},
author = {{F. Silva}, P. Georgieva},
file = {:home/fabio/Desktop/IEETA{\_}overview{\_}AutomatedSkinLesionDiagnosis{\_}01Nov2018.pdf:pdf},
keywords = {computer-assisted dermatology,deep learning,machine learning,medical imaging,mobile applications,self-surveillance,skin lesions},
pages = {1--25},
title = {{Computer-Assisted Diagnosis of Skin Lesions : An Overview from Self-Surveillance to Deep Learning}},
year = {2018}
}
@article{Brinker2018,
abstract = {BACKGROUND State-of-the-art classifiers based on convolutional neural networks (CNNs) were shown to classify images of skin cancer on par with dermatologists and could enable lifesaving and fast diagnoses, even outside the hospital via installation of apps on mobile devices. To our knowledge, at present there is no review of the current work in this research area. OBJECTIVE This study presents the first systematic review of the state-of-the-art research on classifying skin lesions with CNNs. We limit our review to skin lesion classifiers. In particular, methods that apply a CNN only for segmentation or for the classification of dermoscopic patterns are not considered here. Furthermore, this study discusses why the comparability of the presented procedures is very difficult and which challenges must be addressed in the future. METHODS We searched the Google Scholar, PubMed, Medline, ScienceDirect, and Web of Science databases for systematic reviews and original research articles published in English. Only papers that reported sufficient scientific proceedings are included in this review. RESULTS We found 13 papers that classified skin lesions using CNNs. In principle, classification methods can be differentiated according to three principles. Approaches that use a CNN already trained by means of another large dataset and then optimize its parameters to the classification of skin lesions are the most common ones used and they display the best performance with the currently available limited datasets. CONCLUSIONS CNNs display a high performance as state-of-the-art skin lesion classifiers. Unfortunately, it is difficult to compare different classification methods because some approaches use nonpublic datasets for training and/or testing, thereby making reproducibility difficult. Future publications should use publicly available benchmarks and fully disclose methods used for training to allow comparability.},
author = {Brinker, Titus Josef and Hekler, Achim and Utikal, Jochen Sven and Grabe, Niels and Schadendorf, Dirk and Klode, Joachim and Berking, Carola and Steeb, Theresa and Enk, Alexander H and von Kalle, Christof},
doi = {10.2196/11936},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brinker et al. - 2018 - Skin Cancer Classification Using Convolutional Neural Networks Systematic Review.pdf:pdf},
issn = {1438-8871},
journal = {Journal of medical Internet research},
keywords = {carcinoma classification,convolutional neural networks,deep learning,lesion classification,melanoma classification,skin cancer},
month = {oct},
number = {10},
pages = {e11936},
pmid = {30333097},
publisher = {Journal of Medical Internet Research},
title = {{Skin Cancer Classification Using Convolutional Neural Networks: Systematic Review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/30333097},
volume = {20},
year = {2018}
}
@article{Jaworek-Korjakowska2018,
abstract = {Background. Malignant melanoma is among the fastest increasing malignancies in many countries. With the help of new tools, such as teledermoscopy referrals between primary healthcare and dermatology clinics, the diagnosis of these patients could be made more efficient. The introduction of a high-quality smartphone with a built-in digital camera may make the early detection more convenient. This study presents novel directions for early detection of malignant melanoma based on a smartphone application. Objectives and Methods. In this study, we concentrate on a precise description of a complex infrastructure of a fully automated computer-aided diagnostic system for early detection of malignant melanoma. The framework has been customized for a dermoscope that is customized to attach to the smartphone to be able to carry out mobile teledermoscopy. The application requirements, architecture, and computational methods as well as behavioral and dynamic aspects have been presented in this paper. Conclusion. This paper presents a broad application architecture, which can be easily customized for rapid deployment of a sophisticated health application. Mobile teledermoscopy is a new horizon that might become in the future the basis of the early detection of pigmented skin lesions as a screening tool for primary care doctors and inexperienced dermatologists.},
author = {Jaworek-Korjakowska, Joanna and Kleczek, Pawel},
doi = {10.1155/2018/5767360},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaworek-Korjakowska, Kleczek - 2018 - ESkin Study on the smartphone application for early detection of malignant melanoma.pdf:pdf},
issn = {15308677},
journal = {Wireless Communications and Mobile Computing},
publisher = {Hindawi Limited},
title = {{ESkin: Study on the smartphone application for early detection of malignant melanoma}},
volume = {2018},
year = {2018}
}
@article{ham10000,
abstract = {Training of neural networks for automated diagnosis of pigmented skin lesions is hampered by the small size and lack of diversity of available datasets of dermatoscopic images. We tackle this problem by releasing the HAM10000 (“Human Against Machine with 10000 training images”) dataset. We collected dermatoscopic images from different populations acquired and stored by different modalities. Given this diversity we had to apply different acquisition and cleaning methods and developed semi-automatic workflows utilizing specifically trained neural networks. The final dataset consists of 10015 dermatoscopic images which are released as a training set for academic machine learning purposes and are publicly available through the ISIC archive. This benchmark dataset can be used for machine learning and for comparisons with human experts. Cases include a representative collection of all important diagnostic categories in the realm of pigmented lesions. More than 50{\%} of lesions have been confirmed by pathology, while the ground truth for the rest of the cases was either follow-up, expert consensus, or confirmation by in-vivo confocal microscopy.},
archivePrefix = {arXiv},
arxivId = {1803.10417},
author = {Tschandl, Philipp and Rosendahl, Cliff and Kittler, Harald},
doi = {10.1038/sdata.2018.161},
eprint = {1803.10417},
file = {:home/fabio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tschandl, Rosendahl, Kittler - 2018 - Data descriptor The HAM10000 dataset, a large collection of multi-source dermatoscopic images of c.pdf:pdf},
issn = {20524463},
journal = {Scientific Data},
month = {aug},
publisher = {Nature Publishing Groups},
title = {{The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions}},
volume = {5},
year = {2018}
}
